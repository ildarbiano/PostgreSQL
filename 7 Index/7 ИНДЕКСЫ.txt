=============================== ВИДЫ ИНДЕКСОВ:
https://www.postgresql.org/docs/14/sql-createindex.html
Самая простая аналогия - оглавление книги: Мы знаем, на какой странице расположена нужная нам информация и можем сразу туда перейти, нам не нужно перелистывать книгу с начала. С индексами тоже самое - всегда знаем, где искать ту или иную информацию.
CREATE [ UNIQUE ] INDEX [ CONCURRENTLY ] [ [ IF NOT EXISTS ] 'name' ] ON [ ONLY ] 'table_name' [ USING method ]
    ( { 'column_name' | ( expression ) } [ COLLATE collation ] [ opclass [ ( opclass_parameter = value [, ... ] ) ] ] [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [, ...] )
    [ INCLUDE ( column_name [, ...] ) ]
    [ WITH ( storage_parameter [= value] [, ... ] ) ]
    [ TABLESPACE tablespace_name ]
    [ WHERE predicate ]
INDEX 'name'			- имя индекса
ON 'table_name'			- имя таблицы
( { 'column_name'		- имя столбца
expression			-"выражение"
collation			-"правило сортировки" 
storage_parameter		- параметр храниения
TABLESPACE tablespace_name	- пространство таблиц
predicate			- сказуемое

------------------------------- Методы - типы индексов в PostgreSQL:
предназначены для разных задач. Каждый тип использует разную структуру хранения и алгоритм, ориентированный на определённые типы индексируемых данных: 
btree		Btee		сбалансированное дерево — самый распространённый тип индекса в PostgreSQL, по умолчанию.  Используется в 99% индексов. Применим для любого типа, который можно отсортировать в чётко определённом линейном порядке. Работает с операторами сравнения >, <, =, >=, <=, BETWEEN и IN и условия пустоты IS NULL и IS NOT NULL. Быстрая сложность.
hash		HASH		предназначены для обеспечения быстрого доступа к данным по равенству. Работает только с условием равенства (=). В условиях IS NULL и IS NOT NULL - не работает.
gist		GiST		Generalized Search Tree — обобщённое поисковое дерево. Базовый шаблон, на основе которого могут реализовываться произвольные схемы индексации, например, Btree, R-деревья и другие схемы индексации. Для построения, отличный от Btee, используют один из нескольких алгоритмов, наиболее подходящих под тип индексируемого поля, поэтому набор операторов зависит от типа поля. Применяется для специфических типов данных: геометрии, сетевые адреса, диапазоны.
spgist		SP-GiST		Space-Partitioned GiST - с разбиением пространства. Метод поддерживает деревья поиска с разбиением, что позволяет работать с различными несбалансированными структурами данных (деревья квадрантов, k-мерные и префиксные деревья). Как и GiST, SP-GiST позволяет разрабатывать дополнительные типы данных с соответствующими методами доступа.
gin		GIN		Generalized Inverted Index - это обобщённый инвертированный индекс. Применяется к составным типам, работа с которыми осуществляется с помощью ключей: массивы, JSONB. Предназначается для случаев, когда индексируемые значения являются составными, а запросы ищут значения элементов в этих составных объектах. Самый распространённый вариант использования индексов GIN & GiST - полнотекстовый поиск по аналогии с Google/Yandex.
brin		BRIN		Block Range Index — метод индексирования для больших таблиц с отсортированными данными, где строки хранятся в определённой последовательности на основе определённого столбца (например, временной метки, даты, целого числа)

------------------------------- НЕДОСТАТКИ ИНДЕКСОВ:
1/		размер индекса может привысить индексируемую таблицу х2 или х3;
2/		вставка в таблицу с индексами дольше, чем "вставка в таблицу без индексов";
3/		Индексы требуют дополнительного места;
4/		Необходимо перестраивать индексы при операциях UPDATE, DELETE, INSERT;
5/		При большом количестве индексов оптимизатору сложно выбрать какой использовать.

------------------------------- ПЛЮСЫ ИНДЕКСОВ:
1/		Ускоряют выборку в операциях SELECT;
2/		При выборке данных только индексного поля, данные из таблицы не выбираются;
3/		Увеличение скорости сортировки по индексному полю;
4/		Обеспечение уникальности (INDEX 'name').

------------------------------- Best Practice:
1/		Выбираем индекс исходя из условий бизнес задачи;
2/		Возможно стоит попробовать разные индексы - результат может отличаться на разных наборах данных;
3/		Не забываем про другие типы индексов, которые рассмотрим на следующем занятии - функциональный и покрывающий - помогут нам на аналитических запросах;
4/		Не забывать анализировать существующие индексы!!! 
5/		Удаляем неиспользуемые индексы;
6/		Добавляем необходимые;
7/		Индексы необходимо обслуживать, то есть их перестройка.




=============================== B-TREE ИНДЕКС:
это структура данных, используемая для организации индексов. Она представляет собой самобалансирующееся дерево поиска, оптимизированное для хранения и извлечения данных в системах с большими объёмами информации. Особенности B-Tree:
Сбалансированность 		— все листья находятся на одном уровне, что обеспечивает стабильную глубину дерева и предсказуемое время поиска.
Эффективный поиск 		— вставка, удаление и поиск выполняются за O(log n), что делает B-Tree эффективным даже при больших объёмах данных.
Поддержка диапазонных запросов 	— благодаря упорядоченной структуре B-Tree подходит для поиска значений в заданном диапазоне.
Минимизация обращений к диску 	— PostgreSQL использует B-Tree с учётом работы с дисковой памятью, уменьшая количество операций ввода-вывода за счёт хранения узлов в страницах фиксированного размера.
------------------------------- Свойства Btree индекса:
https://habr.com/ru/companies/postgrespro/articles/330544/
Создаётся по-умолчанию. Применим для любого типа таблиц, который можно отсортировать в чётко определённом линейном порядке. Поддерживает:
		-операторы сравнения >, <, =, >=, <=, BETWEEN и IN;
		-условия пустоты IS NULL и IS NOT NULL;
		-операторы поиска подстроки LIKE и ~, если искомая строка закреплена в начале шаблона (например str LIKE 'search%'). % - заменяет любое количество символов;
		-регистронезависимые операторы поиска подстроки ILIKE и ~* (но только в том случае, если искомая строка начинается с символа, который одинаков и в верхнем, и в нижнем регистре, например, числа).
------------------------------- Принцип работы Btree индекса:
B-Tree строит дерево по отсортированному массиву (каждый уровень отсортирован). Именно благодаря сортировке работают все операторы сравнения. Влияние на запросы:
Точечный поиск 			— очень быстрый — находит нужное значение за несколько шагов.
Диапазонный запрос 		— B-Tree эффективно находит начало диапазона и затем последовательно считывает подходящие узлы.
Сортировка (ORDER BY) 		— если столбец отсортирован в индексе, можно вернуть данные по порядку без дополнительной сортировки.
JOIN 				— при соединении, если во второй таблице есть индекс B-Tree по ключу соединения, можно быстро находить соответствия, избегая полного сканирования.
------------------------------- BTREE - BALANCED TREE, not binary!
Сбалансирванное дерево, то есть много веток для перехода.
https://www.cybertec-postgresql.com/en/b-tree-index-deduplication/ -- website is blocked! Дедубликация
------------------------------- BTREE поиск по равенству =42:
Деревое:
Числа с которыми сравниваем: 4, 32, 64;				-- ищем по равенству "=42". 42 находится между 32 и 64, но первая в сравнении 32, поэтому спускаемся по ней.
Переходим на те ветки, где эти числа имеются, в нашем случае: 
4, 16, 25
32, 43, 49							-- по результатам сравнения спускаемся по первой, "32"
64, 79, 89
Спускаемся до "листьев", которые содержат на страницы с данными. То есть, по индексу быстро находится информаци о местоположении страницы с данными. Листья бинарны, поэтому там находится 42, где записаны данные о местоположении на диске.
------------------------------- BTREE поиск по НЕравенству <33:
Деревое:
Числа с которыми сравниваем: 4, 32, 64;				-- ищем по НЕравенству "<33". 33 находится между 32 и 64, но первая в сравнении 32, поэтому спускаемся по ней.
4, 16, 25
32, 43, 49							-- по результатам сравнения спускаемся по первой, "32"
64, 79, 89
Спускаемся до "листьев", которые содержат на страницы с данными. выбираем все значения до 33.
------------------------------- BTREE ПЛЮСЫ И МИНУСЫ:
+		Довольно быстрый индекс - сложность O(log n) Вычислительная сложность:https://ru.wikipedia.org/wiki/%D0%92%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D1%8C;
+		Широкий диапазон условий для выборки по условиям.
-		Если при очередном добавлении/изменении/удалении значения требуется балансировка - довольно медленно. Именно поэтому изначально плотность заполнения 90%;
-		Необходимо их обслуживать - будет рассмотрено дальше в курсе;
-		Работает хорошо только с простыми типами данных (числа, даты, денежные);
-		Работает со строками, только если ищем по шаблону с начала строки (%АБВ).
------------------------------- O(log n):
логарифмическая сложность алгоритма, которая означает, что время выполнения растёт медленно с увеличением размера входных данных (n). Другими словами, алгоритм становится медленнее, но не линейно, а медленнее в соответствии с логарифмической функцией. Пример алгоритма с оценкой временной сложности O(log n) — бинарный поиск. В этом алгоритме на каждом шаге половина данных отсекается, и поиск продолжается в оставшейся половине. Алгоритмы с оценкой временной сложности O(log n) эффективны и быстры при работе с большими объёмами данных, так как их производительность ухудшается медленно с увеличением размера данных. 


=============================== https://www.db-fiddle.com/
онлайн-инструмента DB Fiddle, который предназначен для тестирования, обмена и совместной работы с фрагментами SQL-кода и схемами баз данных. Инструмент поддерживает такие системы управления базами данных, как MySQL, PostgreSQL и SQLite. Полезен для обучения SQL, тестирования проектов баз данных и сотрудничества в проектах, связанных с базами данных. 
------------------------------- DDL (Data Definition Language) в PostgreSQL:
команды для создания и изменения структуры базы данных. Некоторые из них:
CREATE. 	Создание новых объектов в базе данных, таких как таблицы, индексы, представления, функции, триггеры и другие.
ALTER. 		Изменение структуры или свойств существующих объектов в базе данных. Например, ALTER TABLE — изменение структуры таблицы, добавление или удаление столбцов, изменение типов данных и другие операции.
DROP. 		Удаление объектов из базы данных. Например, DROP TABLE — удаление таблицы и связанных с ней данных и индексов.
TRUNCATE. 	Удаления всех записей из таблицы, сохраняя структуру таблицы.
------------------------------- DML (Data Manipulation Language) в PostgreSQL:
набор команд SQL для работы непосредственно с данными в таблицах. Они позволяют добавлять, изменять и удалять записи. Основные команды DML:
SELECT 		Извлечение данных из таблиц;
INSERT		Добавление новых записей;
UPDATE		Изменение существующих записей;
DELETE		Удаление записей;
MERGE		Комбинированная операция вставки/обновления (не во всех СУБД).
------------------------------- Простой индекс: create index uk_test_id on test(id);
https://www.db-fiddle.com/f/97z9hNo3ZqFCXUvN9DNAV5/0
--		комментирование строки
Bitmap Index Scan on idx_test_id (cost=0.00..6.17 rows=250 width=0) 	- Индексное Сканирование. B-TREE (5). Execution time: 1.82ms
Seq Scan on test (cost=0.00..787.88 rows=162 width=68)			- Без индекса, просмотрит укзанное количество записей (50'000). Execution time: 0.86ms
------------------------------- Уникальный индекс: create unique index uk_test_col2 on test(col2);
https://www.db-fiddle.com/f/v98FqExg2Lw7MLeb2PKPhR/0 
Не забываем, что если не добавить описание NOT NULL 			- возможны аномалии NULL != NULL


=============================== СОСТАВНОЙ ИНДЕКС, ПО ВЫРАЖЕНИЯМ И ЧАСТИЧНЫЙ:
Состоит из 2-х, и более, полей одной таблицы. Основная задача, чтобы после того, как найдены нужные строки, например, по полю 1, не идти в основную таблицу за другими данными по полю 2. Сначала строится btree по первому полю, потом внутри маленькое btree по второму полю.
------------------------------- Составной индекс: create index uk_test_id_col2 on test(id, col2);
https://www.db-fiddle.com/f/ujFT64yqZJPdD3kKu3ghkB/0 
CREATE INDEX idx_test_id_is_okay ON test(id, is_okay);    
Есть разновидность - покрывающий индекс:
------------------------------- Составной, но Покрывающий индекс: 
Основное отличие от составного - индекс строится только по 1-му полю, остальные данные просто лежат в листьях. Соответственно строится быстрее и меньше размер, но поиск и по включенным полям будет без индекса. 
CREATE UNIQUE INDEX title_idx ON films (title) INCLUDE (director, rating);
------------------------------- Функциональный индекс: 
Индекс строится не на поле, а на функцию от поля или нескольких полей и именно это значение и хранится в индексе. Соответственно, использоваться такой индекс будет только тогда, когда при поиске будет использована соответствующая функция. Какую функцию мы создаём в DDL, такую же используем в DML.
CREATE INDEX uk_test_name ON test(LOWER(name));				- функция LOWER приводит к нижнему регистру
https://www.db-fiddle.com/f/iCsikL3HGn7Wcp3FzxEfNf/1 
------------------------------- Частичный индекс:
Индекс создается на небольшую часть таблицы по какому-либо условию. Например, есть поставщики, ID до 100 крупные с постоянными заказами, после 100 одноразовые - зачем нам по ним индекс.
CREATE INDEX uk_test_name ON test(id) WHERE id < 100;
https://www.db-fiddle.com/f/m3MQH8J7XrZMYJEm8zyMnc/1 



=============================== ПОЛНОТЕКСТОВЫЙ ПОИСК или просто поиск текста:
https://postgrespro.ru/docs/postgresql/14/textsearch 
это возможность находить документы на естественном языке, соответствующие запросу, и, возможно, дополнительно сортировать их по релевантности для этого запроса. 
Задача 			— найти все документы, содержащие слова запроса, и выдать их отсортированными по степени соответствия запросу. 
Предназначение 		- ранжирование слов и ускорение поиска по тексту.
SELECT 'a fat cats sat on a mat and ate a fat rat'::tsvector @@ 'rat & cat'::tsquery;
::tsquery		- тип данных; 
::tsvector		- тип данных.
------------------------------- tsvector:
тип данных в PostgreSQL, предназначенный для полнотекстового поиска. Он представляет документ в виде, оптимизированном для текстового поиска, — хранит отсортированный список нормализованных слов (лексем). Особенности tsvector:
	Нормализует слова, объединяя их варианты в одно слово;
	Автоматически сортирует лексемы и удаляет повторяющиеся слова перед хранением в таблице;
	Добавляет позиции лексем в документе, которые используются для ранжирования результатов поиска;
	Позволяет маркировать лексемы весами (A, B, C или D), чтобы подчеркнуть их важность.
Предполагается, что в сохраняемом значении слова уже нормализованы приложением. Поэтому исходный документ обычно следует обработать функцией: 
SELECT * from test where to_tsvector(col2) @@ to_tsquery('abs');
to_tsvector			- нормализующей слова для поиска (см. в 74 Задание)
to_tsquery			- нормализующей слова и преобразует в спец формат.
@@				- оператор совпадения: проверяет совпажает ли текстовый вектор текстовому запросу, возвращает:
					true-если совпадает;
					false-если не совпадает.
------------------------------- tsquery:
тип данных в PostgreSQL, который представляет поисковые запросы для полнотекстового поиска. Он позволяет указывать условия поиска, содержащие слова или фразы индексированного документа. Тип tsquery поддерживает логические операторы, что делает его гибким для создания сложных запросов. Формат: Значение tsquery хранит лексемы (слова) для поиска и комбинирует их. Некоторые особенности формата: 
	Логические операторы & (И), | (ИЛИ) и ! (НЕ). Для группировки операторов можно использовать круглые скобки;
	Опционально лексемам в tsquery может назначаться одна и более букв с весом, которые ограничивают при поиске совпадение этих лексем только с лексемами в tsvector, имеющими совпадающий вес;
	Лексемам в tsquery может быть назначен специальный символ *, чтобы указать совпадение по префиксу. Например, запрос «super:*» будет совпадать с любым словом в tsvector, которое начинается на «super».
Операторы: Некоторые операторы, которые можно использовать в запросах tsquery:
tsquery && tsquery 		— объединяет два запроса, создавая запрос, который сопоставляет документы, соответствующие обоим входным запросам.
tsquery || tsquery 		— объединяет два запроса, создавая запрос, который сопоставляет документы, соответствующие любому из входных запросов.
!! tsquery			— отменяет tsquery, создавая запрос, который соответствует документам, которые не соответствуют входному запросу.
tsquery <-> tsquery		— создаёт фразеологический запрос, который совпадает, если два входных запроса совпадают по последовательным лексемам.
Функции: Для преобразования запроса к типу tsquery в PostgreSQL есть функции, например:
to_tsquery 			— создаёт значение tsquery из текста запроса, который может состоять из простых фрагментов, разделённых логическими операторами.
plainto_tsquery 		— преобразует неформатированный текст запроса в значение tsquery, анализирует и нормализует текст, а затем между оставшимися словами вставляет операторы & (И).
phraseto_tsquery 		— анализирует и нормализует текст, вставляет оператор <-> (ПРЕДШЕСТВУЕТ) между словами.
------------------------------- ИНДЕКСИРОВАНИЕ:
заключается в предварительной обработке документов и сохранении индекса для последующего быстрого поиска. PostgreSQL использует словари для преобразования текста в лексемы. Эти словари определяют стоп-слова, которые следует игнорировать, и объединяют разные словоформы в одну лексему. Важно: тип tsvector сам по себе не выполняет нормализацию слов. Предварительная обработка включает следующие операции. 
-	Разбор документов на фрагменты: 				Преобразование документа в tsvector с помощью функции to_tsvector. Функция разбирает текстовый документ на фрагменты, сводит фрагменты к лексемам и возвращает значение tsvector, в котором перечисляются лексемы и их позиции в документе. При этом полезно выделить различные классы фрагментов, например, числа, слова, словосочетания, почтовые адреса и т. д.;
-	Преобразование фрагментов в лексемы;
-	Хранение документов в форме, подготовленной для поиска: 	Например, каждый документ может быть представлен в виде сортированного массива нормализованных лексем.
------------------------------- Лексемы:
это нормализованные фрагменты текста, в которых разные словоформы приведены к одной. Например, буквы верхнего регистра приводятся к нижнему, а из слов обычно убираются окончания. Благодаря этому можно находить разные формы одного слова, не вводя вручную все возможные варианты
------------------------------- ИНДЕКСИРОВАНИЕ ПОЛНОТЕКСТОВОГО ПОИСКА:
CREATE INDEX idx ON test USING GIN (to_tsvector('english',col2)); в поиске лексем будет использоваться индекс GIN на english для колонки col2.
в поиске, при использовании той же функции, будет использован индекс!
select * from test where to_tsvector('english',col2) @@ to_tsquery('abs'); Важно! функции to_tsvector('english',col2)) и to_tsvector(col2) - разные!!!
Несмотря на значение языка по умолчанию english - количество аргументов разное!!! Запрос может происходить без индекса GIN, если атрибут языка не указать.
Реализация для русского языка не самая лучшая, как мы уже увидели на практике - возможно есть смысл использовать для этого выгрузку в ElasticSearch (https://www.elastic.co/elasticsearch/)
Для английских языков есть несколько словарей, можно с ними поэкспериментировать для более лучшего распознавания https://postgrespro.ru/docs/postgresql/14/textsearch-dictionaries 
Важно для индексов - разное количество аргументов - вызываться будут разные функции
http://www.sai.msu.su/~megera/postgres/talks/fts_pgsql_intro.html
https://habr.com/ru/post/442170/ 



=============================== СТАТИСТИКА:
Статистика содержит "границы распределения данных" в таблице, т.е., например:
	знает сколько городов у нас начинаются с букв А по В в поле город;
	следовательно, планировщик уже будет знать сколько выделять памяти.
Postgres по границам "границы распределения данных в таблице" может предположить потребности запросов.
Статистика по данным в таблицах ОТВЕЧАЕТ НА ВОПРОСЫ:
	-Как планировщик определяет что использовать: индекс или последовательное сканирование?
	-Сколько выделять памяти для результата запроса, ведь в одном случае может вернуться 2 записи, а при другом условии 200 000? 
		.если выделить мало памяти, результат не поместится и будет создана временная таблица на диске, а это медленно. 
		.если выделить много памяти - на небольшой результат бесполезно расходуется память...
Поскольку сбор статистики несколько увеличивает накладные расходы (тратим больше ресурсов OveRHeAD - накладные) при выполнении запроса, есть возможность настроить СУБД так, чтобы выполнять или не выполнять сбор статистической информации. By Default собирается минимальная статистика методом семплирования.
------------------------------ Метод семплирования (сэмплирования, SAMPLING-выборка) в PostgreSQL:
— это подход к сбору статистики, при котором фиксируется заданная доля запросов из большого количества. Это позволяет: 
	-Снизить нагрузку на блокировки, так как фиксируется лишь часть запросов. 
	-Анализировать поведение запросов во времени, выявлять проблемные участки и принимать обоснованные решения по оптимизации. 
	-Получать статистику по событиям ожидания, например, для выявления проблем зависимостей для запросов, выполняющихся дольше, чем ожидается. 
Принцип работы семплирования/выборки - выборка небольшое количество записей, то есть не все 100%. Параметр % выборки можно поменять, принято считать, что 5% записей даёт примерно такой же результат на 100%.  Метод семплирования/выборки позволяет:
	-Отфильтровать лишь заданную долю запросов из большого количества. Например, в расширении pg_stat_statements фиксируется не каждый запрос, а, например, каждый второй (при sample_rate=0,5);
	-Учитывать, что в статистику попадают не все запросы — это снижает полноту собираемой информации, особенно при отладке или анализе редких, но проблемных запросов;
	-Автоматизировать сбор статистики — например, в расширении pg_wait_sampling запускается специальный рабочий процесс, который собирает статистику по событиям ожидания для каждого процесса. 
Список стандартных параметров Postgres, котороые можно адаптировать под текущие задачи:
track_activities 		включает мониторинг текущих команд, выполняемых любым серверным процессом;
track_counts 			определяет необходимость сбора статистики по обращениям к таблицам и индексам;
track_functions 		включает отслеживание использования пользовательских функций;
track_io_timing 		включает мониторинг времени чтения и записи блоков.
------------------------------ ТАБЛИЦЫ СТАТИСТИКИ:
много, вот основные табоицы:
------------------------------ PG_STAT_DATABASE
pg_stat_database		Предоставит информацию, которую мы анализируем для оптимизации наших запросов:
	Как много информации получаем из кэша (если мы не попадаем в кэш);
	Как часто бывают проблемы с транзакциями (обрываются, ...).
	Сколько было COMMIT (xact_commit), ROLLBACK (xact_rollback), DEADLOCK and so on.
pg_stat_database		для Data Base. Можно смотреть раз в час и смотреть изменения, для построения мониторинга.
------------------------------ PG_STAT_ACTIVITY
pg_stat_activity		Содержит в себе по одной строке на каждый процесс сервера, так как ! любое подключение к серверу порождает форк/fork основного процесса. Каждый fork, также, отображается в этом представлении. См. Мониторинг Postgres. 
	Увидим кто подключился к процессу;
	Какие запросы выполняются;
	Сколько выполняются по времени.
pg_stat_activity		для Data Base.
------------------------------ PG_STAT_USER_TABLES
pg_stat_user_tables		собрана статистика, что происходит с таблицей. 
	Сколько строк (вместо COUNT (*));
	Сколько мёртвых строк и т.д.
pg_stat_user_tables		для Tables.
------------------------------ PG_STAT_USER_INDEXES
pg_stat_user_indexes		статистика по используемым индексам.
	Сколько раз использовался, чтобы избавляться от неиспользуемых индексов;
	Какой объём информации индекс выдавал;
	
	

=============================== ОБСЛУЖИВАНИЕ ИНДЕКСОВ:
1/ Появляются (также и в индексах) мертвые строки (при постоянном обновлении и удалении полей), не только в файлах данных, но и в индексе. Соответственно необоснованно растет размер, занимает место в памяти, как следствие (SELECT * FROM pgstatindex('pgbench_accounts_pkey') \gx):	
								-потеря производительности (индексов и т.д.);
2/ Мониторинг использование индексов!!				-ненужные удаляем (pg_stat_user_indexes);
3/ Профилирование						-отсутствующие индексы добавляем;
4/ Обслуживание							-перестройка индекса для оптимизации производительности.
------------------------------- pgbench:
— утилита для тестирования производительности PostgreSQL. Она входит в комплект поставки СУБД PostgreSQL. Цель: симулировать различные нагрузки на базу данных, измерять показатели производительности и выявлять области для оптимизации. Принцип работы: Pgbench многократно выполняет заданную последовательность SQL-команд, возможно, в нескольких параллельных соединениях, и рассчитывает среднюю производительность в виде транзакций в секунду (TPS). По умолчанию утилита тестирует сценарий, основанный на модели TPC-B, в котором каждая транзакция включает пять команд SELECT, UPDATE и INSERT. Можно протестировать и другие сценарии, создав собственные скрипты транзакций. Важно: 
результаты тестирования с помощью pgbench могут быть менее достоверными, если само приложение становится источником нагрузки при большом количестве клиентских сессий. Чтобы минимизировать это влияние, рекомендуется запускать pgbench на отдельной машине, а не на том же сервере, где работает база данных. 
------------------------------- Обязательно смотреть состав индексов и перестраивать INDEX:
1/	при большой фрагментарности листьев (leaf_fragmentation) индекса / 49.9-очень много;
2/	при низкой средней плотности avg_leaf_density / 83,9 - низко;
3/	при большом количестве пустых или удаленных листьев deleted_pages / empty_pages;
!! REINDEX CONCURRENTLY - только конкурентная перестройка индексов, иначе нужна полная блокировка таблицы !! простой REINDEX - УРОНИТ ПРОМЫШЛЕННЫЙ КОНТУР.


